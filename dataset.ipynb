{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "* Run the code starting from 'Dataset Creation' up to Synthetic Data Generation. You only need to do this once\n",
    "* Then, the 'Synthetic Data Generation' section will contain everything you need for generating synthetic data from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation\n",
    "1) Download the CNN/Dailymail dataset into the folder `datasets/`. The folder should be named `cnn_dailymail` already, and the train `.csv` should be in `datasets/cnn_dailymail/train.csv` (or change the directory below as needed)\n",
    "2) create the directory `datasets/cnn_parsed`\n",
    "3) Run this section of the notebook. This should remove all the dailymail and duplicate articles and save the new train test val split into the folder above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_dir_in = 'datasets/cnn_dailymail/'\n",
    "dataset_dir_out = 'datasets/cnn_parsed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train dataset\n",
    "def load_and_parse(dataset = 'train'):\n",
    "    df = pd.read_csv(dataset_dir_in + dataset + '.csv')\n",
    "    df = df[df.article.str.contains('CNN')]\n",
    "    df = df.drop_duplicates('article')\n",
    "    return df\n",
    "\n",
    "df_train = load_and_parse('train')\n",
    "df_test = load_and_parse('test')\n",
    "df_val = load_and_parse('validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_train, df_val, df_test])\n",
    "# df_train, df_val = train_test_split(df, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_articles_per_split = 128\n",
    "\n",
    "def create_splits(df, num_articles_per_split):\n",
    "    df = df.sort_values('id')\n",
    "    splits = np.array(range(df.shape[0]))\n",
    "    splits = splits // num_articles_per_split\n",
    "    df['split'] = splits\n",
    "    return df\n",
    "\n",
    "df = create_splits(df, num_articles_per_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(dataset_dir_out + 'all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Below, make sure the directories match with the ones you created\n",
    "* Then specify 'splits' to choose which splits you want to generate data for. Kerem: 0-150, Lillian: 151-300, Emma: 301-450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_4.csv\n",
      "train_15.csv\n",
      "train_29.csv\n",
      "train_409.csv\n",
      "train_353.csv\n",
      "train_347.csv\n",
      "train_390.csv\n",
      "train_384.csv\n",
      "train_385.csv\n",
      "train_391.csv\n",
      "train_346.csv\n",
      "train_352.csv\n",
      "train_408.csv\n",
      "train_28.csv\n",
      "train_14.csv\n",
      "train_5.csv\n",
      "train_7.csv\n",
      "train_16.csv\n",
      "train_378.csv\n",
      "train_344.csv\n",
      "train_350.csv\n",
      "train_387.csv\n",
      "train_393.csv\n",
      "train_392.csv\n",
      "train_386.csv\n",
      "train_351.csv\n",
      "train_345.csv\n",
      "train_379.csv\n",
      "train_17.csv\n",
      "train_6.csv\n",
      "train_2.csv\n",
      "train_13.csv\n",
      "train_341.csv\n",
      "train_355.csv\n",
      "train_369.csv\n",
      "train_382.csv\n",
      "train_396.csv\n",
      "train_397.csv\n",
      "train_383.csv\n",
      "train_368.csv\n",
      "train_354.csv\n",
      "train_340.csv\n",
      "train_12.csv\n",
      "train_3.csv\n",
      "train_1.csv\n",
      "train_38.csv\n",
      "train_10.csv\n",
      "train_356.csv\n",
      "train_342.csv\n",
      "train_395.csv\n",
      "train_381.csv\n",
      "train_380.csv\n",
      "train_394.csv\n",
      "train_343.csv\n",
      "train_357.csv\n",
      "train_11.csv\n",
      "train_39.csv\n",
      "train_0.csv\n",
      "train_62.csv\n",
      "train_318.csv\n",
      "train_330.csv\n",
      "train_324.csv\n",
      "train_325.csv\n",
      "train_331.csv\n",
      "train_319.csv\n",
      "train_63.csv\n",
      "train_61.csv\n",
      "train_49.csv\n",
      "train_327.csv\n",
      "train_333.csv\n",
      "train_332.csv\n",
      "train_326.csv\n",
      "train_48.csv\n",
      "train_60.csv\n",
      "train_58.csv\n",
      "train_64.csv\n",
      "train_70.csv\n",
      "train_322.csv\n",
      "train_336.csv\n",
      "train_337.csv\n",
      "train_323.csv\n",
      "train_71.csv\n",
      "train_65.csv\n",
      "train_59.csv\n",
      "train_67.csv\n",
      "train_335.csv\n",
      "train_321.csv\n",
      "train_309.csv\n",
      "train_308.csv\n",
      "train_320.csv\n",
      "train_334.csv\n",
      "train_66.csv\n",
      "train_72.csv\n",
      "train_57.csv\n",
      "train_43.csv\n",
      "train_339.csv\n",
      "train_311.csv\n",
      "train_305.csv\n",
      "train_304.csv\n",
      "train_310.csv\n",
      "train_338.csv\n",
      "train_42.csv\n",
      "train_56.csv\n",
      "train_40.csv\n",
      "train_54.csv\n",
      "train_68.csv\n",
      "train_306.csv\n",
      "train_312.csv\n",
      "train_313.csv\n",
      "train_307.csv\n",
      "train_69.csv\n",
      "train_55.csv\n",
      "train_41.csv\n",
      "train_45.csv\n",
      "train_51.csv\n",
      "train_303.csv\n",
      "train_317.csv\n",
      "train_316.csv\n",
      "train_302.csv\n",
      "train_50.csv\n",
      "train_44.csv\n",
      "train_52.csv\n",
      "train_46.csv\n",
      "train_314.csv\n",
      "train_328.csv\n",
      "train_329.csv\n",
      "train_301.csv\n",
      "train_315.csv\n",
      "train_47.csv\n",
      "train_53.csv\n",
      "all_6.csv\n",
      "train_34.csv\n",
      "train_20.csv\n",
      "train_372.csv\n",
      "train_366.csv\n",
      "train_400.csv\n",
      "train_399.csv\n",
      "train_398.csv\n",
      "train_367.csv\n",
      "train_401.csv\n",
      "train_373.csv\n",
      "train_21.csv\n",
      "train_35.csv\n",
      "all_7.csv\n",
      "all_5.csv\n",
      "train_23.csv\n",
      "train_37.csv\n",
      "train_359.csv\n",
      "train_403.csv\n",
      "train_365.csv\n",
      "train_371.csv\n",
      "train_370.csv\n",
      "train_402.csv\n",
      "train_364.csv\n",
      "train_358.csv\n",
      "train_36.csv\n",
      "train_22.csv\n",
      "all_4.csv\n",
      "all_0.csv\n",
      "train_26.csv\n",
      "train_32.csv\n",
      "train_360.csv\n",
      "train_406.csv\n",
      "train_374.csv\n",
      "train_348.csv\n",
      "train_349.csv\n",
      "train_375.csv\n",
      "train_361.csv\n",
      "train_407.csv\n",
      "train_33.csv\n",
      "train_27.csv\n",
      "all_1.csv\n",
      "train_8.csv\n",
      "all_3.csv\n",
      "train_19.csv\n",
      "train_31.csv\n",
      "train_25.csv\n",
      "train_377.csv\n",
      "train_405.csv\n",
      "train_363.csv\n",
      "train_388.csv\n",
      "train_389.csv\n",
      "train_404.csv\n",
      "train_362.csv\n",
      "train_376.csv\n",
      "train_410.csv\n",
      "train_24.csv\n",
      "train_18.csv\n",
      "all_2.csv\n",
      "train_9.csv\n"
     ]
    }
   ],
   "source": [
    "import data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def create_lookup_table(dir = 'datasets/synthetic/summary/'):\n",
    "    files = [f for f in listdir(dir) if isfile(join(dir, f))]\n",
    "\n",
    "    lookup_df = None\n",
    "    for f in files:\n",
    "        print(f)\n",
    "        loc = dir + f\n",
    "        if lookup_df is None:\n",
    "            lookup_df = pd.read_csv(loc)\n",
    "        else:\n",
    "            df2 = pd.read_csv(loc)\n",
    "            lookup_df = pd.concat([lookup_df, df2])\n",
    "\n",
    "    unique_ids = lookup_df.id.unique()\n",
    "    id_lookup = {}\n",
    "    for idx in unique_ids:\n",
    "        id_lookup[idx] = 1\n",
    "\n",
    "    return id_lookup\n",
    "\n",
    "id_lookup = create_lookup_table()\n",
    "\n",
    "def is_processed(row):\n",
    "    try:\n",
    "        idx = id_lookup[row['id']]\n",
    "        return False\n",
    "    except:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL DATA\n",
      "83558\n",
      "REMAINING\n",
      "(50047, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "653"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_csv('datasets/cnn_parsed/all.csv')\n",
    "print('ALL DATA')\n",
    "print(df_all.shape[0])\n",
    "\n",
    "df_all = df_all[df_all.apply(is_processed, axis = 1)]\n",
    "print('REMAINING')\n",
    "print(df_all.shape)\n",
    "\n",
    "task = 'summary' # summary or qna\n",
    "synthetic_data_dir = f'datasets/synthetic/{task}/'\n",
    "\n",
    "if task == 'summary':\n",
    "    generator = data.SummaryGenerator()\n",
    "else:\n",
    "    generator = data.QnAGenerator()\n",
    "\n",
    "total_splits = df_all.split.max() + 1\n",
    "\n",
    "total_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Parsing split 200 -----\n",
      "----- Number of articles to parse: 128 -----\n",
      "----- ELAPSED TIME -----\n",
      "256.5 seconds\n",
      "----- Parsing split 201 -----\n",
      "----- Number of articles to parse: 128 -----\n",
      "----- ELAPSED TIME -----\n",
      "263.0 seconds\n",
      "----- Parsing split 202 -----\n",
      "----- Number of articles to parse: 128 -----\n",
      "----- ELAPSED TIME -----\n",
      "264.3 seconds\n",
      "----- Parsing split 203 -----\n",
      "----- Number of articles to parse: 128 -----\n",
      "['[keywords] \"Senate\"', ' \"repeal\"', ' \"don\\'t ask', ' don\\'t tell\"', ' \"filibuster\"', ' \"bipartisan\"\\n']\n",
      "----- GOT BAD RESPONSE FOR KEYWORDS ------\n",
      "----- ELAPSED TIME -----\n",
      "272.7 seconds\n",
      "----- Parsing split 204 -----\n",
      "----- Number of articles to parse: 128 -----\n",
      "['[keywords] \"don\\'t ask', ' don\\'t tell\"', ' \"Gates\"', ' \"Pentagon\"', ' \"repeal\"', ' \"military\"\\n']\n",
      "----- GOT BAD RESPONSE FOR KEYWORDS ------\n",
      "----- ELAPSED TIME -----\n",
      "282.7 seconds\n",
      "----- Parsing split 205 -----\n",
      "----- Number of articles to parse: 128 -----\n",
      "----- ELAPSED TIME -----\n",
      "267.4 seconds\n",
      "----- Parsing split 206 -----\n",
      "----- Number of articles to parse: 128 -----\n",
      "----- ELAPSED TIME -----\n",
      "255.6 seconds\n",
      "----- Parsing split 207 -----\n",
      "----- Number of articles to parse: 128 -----\n",
      "----- ELAPSED TIME -----\n",
      "299.0 seconds\n",
      "----- Parsing split 208 -----\n",
      "----- Number of articles to parse: 128 -----\n",
      "----- ELAPSED TIME -----\n",
      "259.7 seconds\n",
      "----- Parsing split 209 -----\n",
      "----- Number of articles to parse: 128 -----\n",
      "----- ELAPSED TIME -----\n",
      "248.0 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "splits = list(range(200, 210))\n",
    "data.process_splits(df_all, generator, splits, synthetic_data_dir = synthetic_data_dir, mode = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create batch api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"batch_requests.jsonl\", \"w\") as f:\n",
    "    for i , (_, row) in enumerate(df_all.iterrows()):\n",
    "        if i == 10000:\n",
    "            break\n",
    "\n",
    "        text = row['article']\n",
    "        idx = row['id']\n",
    "\n",
    "        id_lookup[idx] = 1\n",
    "\n",
    "        custom_id = f'request-summary-{idx}'\n",
    "\n",
    "        system_prompt = generator.system_prompt\n",
    "        \n",
    "        messages = [\n",
    "            {'role' : 'system', 'content' : system_prompt},\n",
    "            {'role' : 'user', 'content' : text}\n",
    "        ]\n",
    "\n",
    "        body = {'model' : 'gpt-4o-mini', 'messages' : messages, 'max_tokens' : 2048, 'temperature' : 0.1}\n",
    "        \n",
    "        line = {'custom_id' : custom_id, 'method' : 'POST', 'url' : '/v1/chat/completions', 'body' : body}\n",
    "        json.dump(line, f)\n",
    "        f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "batch_input_file = client.files.create(\n",
    "file=open(\"batch_requests.jsonl\", \"rb\"),\n",
    "purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_675b4c357e688190b7147f69fc698aab', completion_window='24h', created_at=1734036533, endpoint='/v1/chat/completions', input_file_id='file-C1tn1nDmPATA7B5gd2TQU8', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1734122933, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Summarization'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "client.batches.create(\n",
    "  input_file_id=batch_input_file.id,\n",
    "  endpoint=\"/v1/chat/completions\",\n",
    "  completion_window=\"24h\",\n",
    "  metadata={\n",
    "    \"description\": \"Summarization\"\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[Model](data=[Model(id='gpt-4o', created=1715367049, object='model', owned_by='system'), Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'), Model(id='gpt-4o-mini', created=1721172741, object='model', owned_by='system'), Model(id='gpt-4o-mini-2024-07-18', created=1721172717, object='model', owned_by='system')], object='list')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse batch responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[keywords] \"Lust', ' Caution\"', ' \"Ang Lee\"', ' \"Wong Chia Chi\"', ' \"Tony Leung\"', ' \"World War II\"\\n']\n",
      "['[keywords] \"CNN\"', ' \"Student News\"', ' \"September 23', ' 2011\"', ' \"transcript\"', ' \"maps\"\\n']\n",
      "['[keywords] \"Navy\"', ' \"don\\'t ask', ' don\\'t tell\"', ' \"gay\"', ' \"Lynne\"', ' \"military\"\\n']\n",
      "['[keywords] \"don\\'t ask', ' don\\'t tell\"', ' \"Obama administration\"', ' \"repeal\"', ' \"military\"', ' \"Log Cabin Republicans\"\\n']\n",
      "['[keywords] \"Lady Gaga\"', ' \"rally\"', ' \"defense bill\"', ' \"don\\'t ask', ' don\\'t tell\"', ' \"Senate\"\\n']\n",
      "['[keywords] \"Darren Manzella\"', ' \"don\\'t ask', ' don\\'t tell\"', ' \"military\"', ' \"discharge\"', ' \"sexual identity\"\\n']\n",
      "['[keywords] \"don\\'t ask', ' don\\'t tell\"', ' \"Pentagon\"', ' \"military\"', ' \"repeal\"', ' \"cohesion\"\\n']\n",
      "['[keywords] \"don\\'t ask', ' don\\'t tell\"', ' \"Patrick Murphy\"', ' \"repeal\"', ' \"military\"', ' \"discrimination\"\\n']\n",
      "['[keywords] \"don\\'t ask', ' don\\'t tell\"', ' \"repeal\"', ' \"military\"', ' \"Gates\"', ' \"certification\"\\n']\n",
      "['[keywords] \"Ron Palillo\"', ' \"Welcome Back', ' Kotter\"', ' \"actor\"', ' \"heart attack\"', ' \"theater\"\\n']\n",
      "['[keywords] \"military\"', ' \"repeal\"', ' \"don\\'t ask', ' don\\'t tell\"', ' \"LGBT\"', ' \"service\"\\n']\n",
      "['[keywords] \"don\\'t ask', ' don\\'t tell\"', ' \"military\"', ' \"survey\"', ' \"equality\"', ' \"civil rights\"\\n']\n",
      "['[keywords] \"Lee Byung-hun\"', ' \"The Good', ' The Bad', ' The Weird\"', ' \"Hollywood\"', ' \"villain\"', ' \"popularity\"  \\n']\n",
      "['[keywords] \"protesters\"', ' \"justice\"', ' \"Brandon McClelland\"', ' \"white supremacists\"', ' \"Paris', ' Texas\"\\n']\n",
      "['[keywords] \"Washington', ' D.C.\"', ' \"CNN\"', ' \"Student News\"', ' \"transcript\"', ' \"map\"\\n']\n",
      "['[keywords] \"EPA\"', ' \"glyphosate\"', ' \"2', '4D\"', ' \"herbicides\"', ' \"public health\"\\n']\n",
      "['[keywords] \"ROTC\"', ' \"don\\'t ask', ' don\\'t tell\"', ' \"Harvard\"', ' \"Yale\"', ' \"military service\"\\n']\n",
      "['[keywords] \"CNN\"', ' \"Student News\"', ' \"December 21', ' 2012\"', ' \"transcript\"', ' \"map\"\\n']\n",
      "['[keywords] \"Mo Farah\"', ' \"10', '000 meters\"', ' \"world championships\"', ' \"Usain Bolt\"', ' \"marathon\"\\n']\n",
      "['[keywords] \"don\\'t ask', ' don\\'t tell\"', ' \"appeals court\"', ' \"Obama administration\"', ' \"military\"', ' \"repeal\"\\n']\n",
      "['[keywords] \"don\\'t ask', ' don\\'t tell\"', ' \"repeal\"', ' \"military\"', ' \"Senate\"', ' \"legislation\"\\n']\n",
      "(9979, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>human_summary</th>\n",
       "      <th>split</th>\n",
       "      <th>gpt_summary</th>\n",
       "      <th>gpt_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7037</td>\n",
       "      <td>02fbe00a8ca19dbd1ddc989bde8f387e1ea34848</td>\n",
       "      <td>Washington (CNN)Nearly 6 in 10 Americans say t...</td>\n",
       "      <td>Most Americans say businesses should not discr...</td>\n",
       "      <td>8</td>\n",
       "      <td>A recent CNN/ORC poll reveals that nearly 60% ...</td>\n",
       "      <td>[same-sex couples, businesses, religious objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1058</td>\n",
       "      <td>02fd53c1bbd8bed0380fdabd56558a6f64ef95be</td>\n",
       "      <td>(CNN Student News) -- August 22, 2014 . It's a...</td>\n",
       "      <td>This page includes the show Transcript .\\nUse ...</td>\n",
       "      <td>8</td>\n",
       "      <td>The CNN Student News program highlights a mira...</td>\n",
       "      <td>[Ebola, Ferguson, statues, doctor, news]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92538</td>\n",
       "      <td>0303ab6df437e8548306512852c9ec65d2c716ef</td>\n",
       "      <td>(CNN) -- Denise Borino-Quinn, who played the w...</td>\n",
       "      <td>Denise Borino-Quinn played the wife of mob bos...</td>\n",
       "      <td>8</td>\n",
       "      <td>Denise Borino-Quinn, known for her role as Gin...</td>\n",
       "      <td>[Denise Borino-Quinn, The Sopranos, cancer, Gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92540</td>\n",
       "      <td>0303f5a5689817bad8af4701708b075fc9d69470</td>\n",
       "      <td>(CNN) -- House Speaker John Boehner and the Pr...</td>\n",
       "      <td>Robert Mnookin: Boehner, Obama in dangerous ga...</td>\n",
       "      <td>8</td>\n",
       "      <td>House Speaker John Boehner and President Barac...</td>\n",
       "      <td>[negotiation, budget, debt ceiling, Boehner, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92541</td>\n",
       "      <td>030435cfe4a74e665130955677fdb29a177066c5</td>\n",
       "      <td>(CNN) -- A school bus wreck killed a young chi...</td>\n",
       "      <td>Ten other children are injured, two critically...</td>\n",
       "      <td>8</td>\n",
       "      <td>A tragic school bus wreck in Indianapolis resu...</td>\n",
       "      <td>[school bus, wreck, child, injured, investigat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        id  \\\n",
       "0        7037  02fbe00a8ca19dbd1ddc989bde8f387e1ea34848   \n",
       "1        1058  02fd53c1bbd8bed0380fdabd56558a6f64ef95be   \n",
       "2       92538  0303ab6df437e8548306512852c9ec65d2c716ef   \n",
       "3       92540  0303f5a5689817bad8af4701708b075fc9d69470   \n",
       "4       92541  030435cfe4a74e665130955677fdb29a177066c5   \n",
       "\n",
       "                                             article  \\\n",
       "0  Washington (CNN)Nearly 6 in 10 Americans say t...   \n",
       "1  (CNN Student News) -- August 22, 2014 . It's a...   \n",
       "2  (CNN) -- Denise Borino-Quinn, who played the w...   \n",
       "3  (CNN) -- House Speaker John Boehner and the Pr...   \n",
       "4  (CNN) -- A school bus wreck killed a young chi...   \n",
       "\n",
       "                                       human_summary  split  \\\n",
       "0  Most Americans say businesses should not discr...      8   \n",
       "1  This page includes the show Transcript .\\nUse ...      8   \n",
       "2  Denise Borino-Quinn played the wife of mob bos...      8   \n",
       "3  Robert Mnookin: Boehner, Obama in dangerous ga...      8   \n",
       "4  Ten other children are injured, two critically...      8   \n",
       "\n",
       "                                         gpt_summary  \\\n",
       "0  A recent CNN/ORC poll reveals that nearly 60% ...   \n",
       "1  The CNN Student News program highlights a mira...   \n",
       "2  Denise Borino-Quinn, known for her role as Gin...   \n",
       "3  House Speaker John Boehner and President Barac...   \n",
       "4  A tragic school bus wreck in Indianapolis resu...   \n",
       "\n",
       "                                        gpt_keywords  \n",
       "0  [same-sex couples, businesses, religious objec...  \n",
       "1           [Ebola, Ferguson, statues, doctor, news]  \n",
       "2  [Denise Borino-Quinn, The Sopranos, cancer, Gi...  \n",
       "3  [negotiation, budget, debt ceiling, Boehner, O...  \n",
       "4  [school bus, wreck, child, injured, investigat...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import data\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "filename = 'datasets/batch_675b4c357e688190b7147f69fc698aab_output.jsonl'\n",
    "\n",
    "generator = data.SummaryGenerator()\n",
    "\n",
    "with open(filename, 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "\n",
    "\n",
    "results = []\n",
    "for json_str in json_list:\n",
    "    result = json.loads(json_str)\n",
    "\n",
    "    id = result['custom_id'].split('-')[2]\n",
    "    text = result['response']['body']['choices'][0]['message']['content']\n",
    "    \n",
    "    try:\n",
    "        out = generator.parse_response(text)\n",
    "        out['id'] = id\n",
    "        out['gpt_summary'] = out.pop('summary')\n",
    "        out['gpt_keywords'] = out.pop('keywords')\n",
    "        results.append(out)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "        print(e)\n",
    "\n",
    "df_out = pd.DataFrame(columns = results[0].keys())\n",
    "for result in results:\n",
    "    for key in result.keys():\n",
    "        result[key] = [result[key]] # otherwise the lists are ignored\n",
    "    df_row = pd.DataFrame.from_dict(result)\n",
    "    df_out = pd.concat([df_out, df_row])\n",
    "    \n",
    "df_all = pd.read_csv('datasets/cnn_parsed/all.csv')\n",
    "df_all = df_all.rename(columns={'highlights' : 'human_summary'})\n",
    "\n",
    "df_merged = pd.merge(df_all, df_out, on='id', how='inner')\n",
    "df_merged.drop(df_merged.columns[df_merged.columns.str.contains('^Unnamed')], axis=1, inplace=True)\n",
    "print(df_merged.shape)\n",
    "df_merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv('datasets/synthetic/batch_0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_4.csv\n",
      "train_15.csv\n",
      "train_29.csv\n",
      "train_409.csv\n",
      "all_200.csv\n",
      "train_353.csv\n",
      "train_347.csv\n",
      "train_390.csv\n",
      "train_384.csv\n",
      "train_385.csv\n",
      "train_391.csv\n",
      "train_346.csv\n",
      "train_352.csv\n",
      "all_201.csv\n",
      "train_408.csv\n",
      "train_28.csv\n",
      "train_14.csv\n",
      "train_5.csv\n",
      "train_7.csv\n",
      "train_16.csv\n",
      "all_203.csv\n",
      "train_378.csv\n",
      "train_344.csv\n",
      "train_350.csv\n",
      "train_387.csv\n",
      "train_393.csv\n",
      "train_392.csv\n",
      "train_386.csv\n",
      "train_351.csv\n",
      "train_345.csv\n",
      "all_202.csv\n",
      "train_379.csv\n",
      "train_17.csv\n",
      "train_6.csv\n",
      "train_2.csv\n",
      "train_13.csv\n",
      "train_341.csv\n",
      "train_355.csv\n",
      "all_206.csv\n",
      "train_369.csv\n",
      "train_382.csv\n",
      "train_396.csv\n",
      "train_397.csv\n",
      "train_383.csv\n",
      "train_368.csv\n",
      "all_207.csv\n",
      "train_354.csv\n",
      "train_340.csv\n",
      "train_12.csv\n",
      "train_3.csv\n",
      "train_1.csv\n",
      "train_38.csv\n",
      "train_10.csv\n",
      "train_356.csv\n",
      "train_342.csv\n",
      "all_205.csv\n",
      "train_395.csv\n",
      "train_381.csv\n",
      "train_380.csv\n",
      "train_394.csv\n",
      "all_204.csv\n",
      "train_343.csv\n",
      "train_357.csv\n",
      "train_11.csv\n",
      "train_39.csv\n",
      "train_0.csv\n",
      "train_62.csv\n",
      "train_318.csv\n",
      "train_330.csv\n",
      "train_324.csv\n",
      "train_325.csv\n",
      "train_331.csv\n",
      "train_319.csv\n",
      "train_63.csv\n",
      "train_61.csv\n",
      "train_49.csv\n",
      "train_327.csv\n",
      "train_333.csv\n",
      "train_332.csv\n",
      "train_326.csv\n",
      "train_48.csv\n",
      "train_60.csv\n",
      "train_58.csv\n",
      "train_64.csv\n",
      "train_70.csv\n",
      "train_322.csv\n",
      "train_336.csv\n",
      "train_337.csv\n",
      "train_323.csv\n",
      "train_71.csv\n",
      "train_65.csv\n",
      "train_59.csv\n",
      "train_67.csv\n",
      "train_335.csv\n",
      "train_321.csv\n",
      "train_309.csv\n",
      "train_308.csv\n",
      "train_320.csv\n",
      "train_334.csv\n",
      "train_66.csv\n",
      "train_72.csv\n",
      "train_57.csv\n",
      "train_43.csv\n",
      "train_339.csv\n",
      "train_311.csv\n",
      "train_305.csv\n",
      "train_304.csv\n",
      "train_310.csv\n",
      "train_338.csv\n",
      "train_42.csv\n",
      "train_56.csv\n",
      "train_40.csv\n",
      "train_54.csv\n",
      "train_68.csv\n",
      "train_306.csv\n",
      "train_312.csv\n",
      "train_313.csv\n",
      "train_307.csv\n",
      "train_69.csv\n",
      "train_55.csv\n",
      "train_41.csv\n",
      "train_45.csv\n",
      "train_51.csv\n",
      "train_303.csv\n",
      "train_317.csv\n",
      "train_316.csv\n",
      "train_302.csv\n",
      "train_50.csv\n",
      "train_44.csv\n",
      "train_52.csv\n",
      "train_46.csv\n",
      "train_314.csv\n",
      "train_328.csv\n",
      "train_329.csv\n",
      "train_301.csv\n",
      "train_315.csv\n",
      "train_47.csv\n",
      "train_53.csv\n",
      "all_6.csv\n",
      "train_34.csv\n",
      "train_20.csv\n",
      "all_209.csv\n",
      "train_372.csv\n",
      "train_366.csv\n",
      "train_400.csv\n",
      "train_399.csv\n",
      "train_398.csv\n",
      "train_367.csv\n",
      "train_401.csv\n",
      "all_208.csv\n",
      "train_373.csv\n",
      "batch_0.csv\n",
      "train_21.csv\n",
      "train_35.csv\n",
      "all_7.csv\n",
      "all_5.csv\n",
      "train_23.csv\n",
      "train_37.csv\n",
      "train_359.csv\n",
      "train_403.csv\n",
      "train_365.csv\n",
      "train_371.csv\n",
      "train_370.csv\n",
      "train_402.csv\n",
      "train_364.csv\n",
      "train_358.csv\n",
      "train_36.csv\n",
      "train_22.csv\n",
      "all_4.csv\n",
      "all_0.csv\n",
      "train_26.csv\n",
      "train_32.csv\n",
      "train_360.csv\n",
      "train_406.csv\n",
      "train_374.csv\n",
      "train_348.csv\n",
      "train_349.csv\n",
      "train_375.csv\n",
      "train_361.csv\n",
      "train_407.csv\n",
      "train_33.csv\n",
      "train_27.csv\n",
      "all_1.csv\n",
      "train_8.csv\n",
      "all_3.csv\n",
      "train_19.csv\n",
      "train_31.csv\n",
      "train_25.csv\n",
      "train_377.csv\n",
      "train_405.csv\n",
      "train_363.csv\n",
      "train_388.csv\n",
      "train_389.csv\n",
      "train_404.csv\n",
      "train_362.csv\n",
      "train_376.csv\n",
      "train_410.csv\n",
      "train_24.csv\n",
      "train_18.csv\n",
      "all_2.csv\n",
      "train_9.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>gpt_summary</th>\n",
       "      <th>gpt_keywords</th>\n",
       "      <th>human_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02268ba08216bf41f800a591340fa3ca516d821b</td>\n",
       "      <td>(CNN) -- A British tourist in the United State...</td>\n",
       "      <td>A British tourist, John Stephen Busby, was kil...</td>\n",
       "      <td>['crash', 'vintage', 'tourist', 'Galveston', '...</td>\n",
       "      <td>Man was in the United States for his 41st wedd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02271084074dc719dfa84594eba2eae7bc5ac51d</td>\n",
       "      <td>(CNN) -- The race is on to locate the latest B...</td>\n",
       "      <td>Banksy is currently showcasing his latest art ...</td>\n",
       "      <td>['Banksy', 'New York', 'art', 'residency', 'so...</td>\n",
       "      <td>Banksy started out as a graffiti artist in wes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02271c690c2e7876fbd1167750e91d360205b8f0</td>\n",
       "      <td>(CNN) -- Late one afternoon in the summer of 2...</td>\n",
       "      <td>The author reflects on her unconventional rela...</td>\n",
       "      <td>['marriage', 'divorce', 'love', 'commitment', ...</td>\n",
       "      <td>Elizabeth Gilbert is the author of \"Eat, Pray,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0228c2331812dc41f4dbac83845761d7e632d400</td>\n",
       "      <td>(CNN) -- Rafael Nadal made light work of Marco...</td>\n",
       "      <td>Rafael Nadal showcased his prowess at the Aego...</td>\n",
       "      <td>['Rafael Nadal', 'Aegon Championships', 'grass...</td>\n",
       "      <td>Rafael Nadal wins his first game on grass in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>022a2cd3f444f0a362aa7d66267cb74ba5bebd94</td>\n",
       "      <td>Jakarta, Indonesia (CNN) -- International flig...</td>\n",
       "      <td>International flights to Bali have been cancel...</td>\n",
       "      <td>['Bali', 'flights', 'volcanic', 'ash', 'Mount ...</td>\n",
       "      <td>An ash cloud has affected flights to the Indon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0  02268ba08216bf41f800a591340fa3ca516d821b   \n",
       "1  02271084074dc719dfa84594eba2eae7bc5ac51d   \n",
       "2  02271c690c2e7876fbd1167750e91d360205b8f0   \n",
       "3  0228c2331812dc41f4dbac83845761d7e632d400   \n",
       "4  022a2cd3f444f0a362aa7d66267cb74ba5bebd94   \n",
       "\n",
       "                                             article  \\\n",
       "0  (CNN) -- A British tourist in the United State...   \n",
       "1  (CNN) -- The race is on to locate the latest B...   \n",
       "2  (CNN) -- Late one afternoon in the summer of 2...   \n",
       "3  (CNN) -- Rafael Nadal made light work of Marco...   \n",
       "4  Jakarta, Indonesia (CNN) -- International flig...   \n",
       "\n",
       "                                         gpt_summary  \\\n",
       "0  A British tourist, John Stephen Busby, was kil...   \n",
       "1  Banksy is currently showcasing his latest art ...   \n",
       "2  The author reflects on her unconventional rela...   \n",
       "3  Rafael Nadal showcased his prowess at the Aego...   \n",
       "4  International flights to Bali have been cancel...   \n",
       "\n",
       "                                        gpt_keywords  \\\n",
       "0  ['crash', 'vintage', 'tourist', 'Galveston', '...   \n",
       "1  ['Banksy', 'New York', 'art', 'residency', 'so...   \n",
       "2  ['marriage', 'divorce', 'love', 'commitment', ...   \n",
       "3  ['Rafael Nadal', 'Aegon Championships', 'grass...   \n",
       "4  ['Bali', 'flights', 'volcanic', 'ash', 'Mount ...   \n",
       "\n",
       "                                       human_summary  \n",
       "0  Man was in the United States for his 41st wedd...  \n",
       "1  Banksy started out as a graffiti artist in wes...  \n",
       "2  Elizabeth Gilbert is the author of \"Eat, Pray,...  \n",
       "3  Rafael Nadal wins his first game on grass in t...  \n",
       "4  An ash cloud has affected flights to the Indon...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import data\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "dir = 'datasets/synthetic/summary/'\n",
    "\n",
    "files = [f for f in listdir(dir) if isfile(join(dir, f))]\n",
    "\n",
    "df = None\n",
    "for f in files:\n",
    "    print(f)\n",
    "    loc = dir + f\n",
    "    if df is None:\n",
    "        df = pd.read_csv(loc)\n",
    "    else:\n",
    "        df2 = pd.read_csv(loc)\n",
    "        df = pd.concat([df, df2])\n",
    "\n",
    "df.drop(df.columns[df.columns.str.contains('^split')], axis = 1, inplace=True)\n",
    "df.drop(df.columns[df.columns.str.contains('^Unnamed')], axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34768,)\n",
      "(34768,)\n",
      "(34768,)\n",
      "(34727,)\n",
      "(34530,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>gpt_summary</th>\n",
       "      <th>gpt_keywords</th>\n",
       "      <th>human_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02268ba08216bf41f800a591340fa3ca516d821b</td>\n",
       "      <td>(CNN) -- A British tourist in the United State...</td>\n",
       "      <td>A British tourist, John Stephen Busby, was kil...</td>\n",
       "      <td>['crash', 'vintage', 'tourist', 'Galveston', '...</td>\n",
       "      <td>Man was in the United States for his 41st wedd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02271084074dc719dfa84594eba2eae7bc5ac51d</td>\n",
       "      <td>(CNN) -- The race is on to locate the latest B...</td>\n",
       "      <td>Banksy is currently showcasing his latest art ...</td>\n",
       "      <td>['Banksy', 'New York', 'art', 'residency', 'so...</td>\n",
       "      <td>Banksy started out as a graffiti artist in wes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02271c690c2e7876fbd1167750e91d360205b8f0</td>\n",
       "      <td>(CNN) -- Late one afternoon in the summer of 2...</td>\n",
       "      <td>The author reflects on her unconventional rela...</td>\n",
       "      <td>['marriage', 'divorce', 'love', 'commitment', ...</td>\n",
       "      <td>Elizabeth Gilbert is the author of \"Eat, Pray,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0228c2331812dc41f4dbac83845761d7e632d400</td>\n",
       "      <td>(CNN) -- Rafael Nadal made light work of Marco...</td>\n",
       "      <td>Rafael Nadal showcased his prowess at the Aego...</td>\n",
       "      <td>['Rafael Nadal', 'Aegon Championships', 'grass...</td>\n",
       "      <td>Rafael Nadal wins his first game on grass in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>022a2cd3f444f0a362aa7d66267cb74ba5bebd94</td>\n",
       "      <td>Jakarta, Indonesia (CNN) -- International flig...</td>\n",
       "      <td>International flights to Bali have been cancel...</td>\n",
       "      <td>['Bali', 'flights', 'volcanic', 'ash', 'Mount ...</td>\n",
       "      <td>An ash cloud has affected flights to the Indon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0  02268ba08216bf41f800a591340fa3ca516d821b   \n",
       "1  02271084074dc719dfa84594eba2eae7bc5ac51d   \n",
       "2  02271c690c2e7876fbd1167750e91d360205b8f0   \n",
       "3  0228c2331812dc41f4dbac83845761d7e632d400   \n",
       "4  022a2cd3f444f0a362aa7d66267cb74ba5bebd94   \n",
       "\n",
       "                                             article  \\\n",
       "0  (CNN) -- A British tourist in the United State...   \n",
       "1  (CNN) -- The race is on to locate the latest B...   \n",
       "2  (CNN) -- Late one afternoon in the summer of 2...   \n",
       "3  (CNN) -- Rafael Nadal made light work of Marco...   \n",
       "4  Jakarta, Indonesia (CNN) -- International flig...   \n",
       "\n",
       "                                         gpt_summary  \\\n",
       "0  A British tourist, John Stephen Busby, was kil...   \n",
       "1  Banksy is currently showcasing his latest art ...   \n",
       "2  The author reflects on her unconventional rela...   \n",
       "3  Rafael Nadal showcased his prowess at the Aego...   \n",
       "4  International flights to Bali have been cancel...   \n",
       "\n",
       "                                        gpt_keywords  \\\n",
       "0  ['crash', 'vintage', 'tourist', 'Galveston', '...   \n",
       "1  ['Banksy', 'New York', 'art', 'residency', 'so...   \n",
       "2  ['marriage', 'divorce', 'love', 'commitment', ...   \n",
       "3  ['Rafael Nadal', 'Aegon Championships', 'grass...   \n",
       "4  ['Bali', 'flights', 'volcanic', 'ash', 'Mount ...   \n",
       "\n",
       "                                       human_summary  \n",
       "0  Man was in the United States for his 41st wedd...  \n",
       "1  Banksy started out as a graffiti artist in wes...  \n",
       "2  Elizabeth Gilbert is the author of \"Eat, Pray,...  \n",
       "3  Rafael Nadal wins his first game on grass in t...  \n",
       "4  An ash cloud has affected flights to the Indon...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(df[col].unique().shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datasets/synthetic/summary_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
