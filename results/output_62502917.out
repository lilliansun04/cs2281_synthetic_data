~/cs2281_synthetic_data ~/cs2281_synthetic_data
~/cs2281_synthetic_data ~/cs2281_synthetic_data ~/cs2281_synthetic_data
Running finetuning_summarization_no_eval.py
Saving results to results/summarization/t5-small_1_no_eval_3
Number of GPUs available: 1
GPU 0: NVIDIA H100 80GB HBM3
Model name: google/flan-t5-small
Output directory: results/summarization/
Scratch directory: /n/netscratch/hlakkaraju_lab/Everyone/lilliansun/synthetic_data/
Unique save name: t5-small_1_no_eval_3
Dataset proportion: 1.0
Summarization train filepath: synthetic/summary_train.csv
Summarization val filepath: synthetic/summary_val.csv
Summarization test filepath: synthetic/summary_test.csv
Batch size: 8
Evaluation steps: 40
Size of input_ids tensor: torch.Size([3000]), dtype: torch.int64
Actual sequence length: 542
Size of input_ids tensor: torch.Size([2736]), dtype: torch.int64
Actual sequence length: 293
Size of input_ids tensor: torch.Size([3000]), dtype: torch.int64
Actual sequence length: 965
{'loss': 11.7623, 'grad_norm': 10.646448135375977, 'learning_rate': 4.769850402761795e-05, 'epoch': 0.05}
{'loss': 4.1082, 'grad_norm': 9.785981178283691, 'learning_rate': 4.539700805523591e-05, 'epoch': 0.09}
{'loss': 3.0156, 'grad_norm': 12.040605545043945, 'learning_rate': 4.3095512082853856e-05, 'epoch': 0.14}
{'loss': 2.6113, 'grad_norm': 12.846781730651855, 'learning_rate': 4.079401611047181e-05, 'epoch': 0.18}
{'loss': 2.2697, 'grad_norm': 13.0380859375, 'learning_rate': 3.849252013808976e-05, 'epoch': 0.23}
{'loss': 1.9973, 'grad_norm': 12.517767906188965, 'learning_rate': 3.619102416570771e-05, 'epoch': 0.28}
{'loss': 1.7561, 'grad_norm': 10.065373420715332, 'learning_rate': 3.3889528193325666e-05, 'epoch': 0.32}
{'loss': 1.591, 'grad_norm': 7.433014392852783, 'learning_rate': 3.1588032220943615e-05, 'epoch': 0.37}
{'loss': 1.4516, 'grad_norm': 5.552554130554199, 'learning_rate': 2.9286536248561568e-05, 'epoch': 0.41}
{'loss': 1.3758, 'grad_norm': 3.800870895385742, 'learning_rate': 2.698504027617952e-05, 'epoch': 0.46}
{'loss': 1.3255, 'grad_norm': 2.6973636150360107, 'learning_rate': 2.468354430379747e-05, 'epoch': 0.51}
{'loss': 1.2858, 'grad_norm': 1.920485258102417, 'learning_rate': 2.238204833141542e-05, 'epoch': 0.55}
{'loss': 1.2591, 'grad_norm': 1.4948347806930542, 'learning_rate': 2.008055235903337e-05, 'epoch': 0.6}
{'loss': 1.2416, 'grad_norm': 1.1854610443115234, 'learning_rate': 1.7779056386651323e-05, 'epoch': 0.64}
{'loss': 1.2196, 'grad_norm': 0.9572250843048096, 'learning_rate': 1.5477560414269276e-05, 'epoch': 0.69}
{'loss': 1.2133, 'grad_norm': 0.8710228800773621, 'learning_rate': 1.3176064441887228e-05, 'epoch': 0.74}
{'loss': 1.2126, 'grad_norm': 0.8230109810829163, 'learning_rate': 1.0874568469505179e-05, 'epoch': 0.78}
{'loss': 1.2045, 'grad_norm': 0.7438555359840393, 'learning_rate': 8.57307249712313e-06, 'epoch': 0.83}
{'loss': 1.2041, 'grad_norm': 0.7831137776374817, 'learning_rate': 6.271576524741082e-06, 'epoch': 0.87}
{'loss': 1.2004, 'grad_norm': 0.6950609683990479, 'learning_rate': 3.970080552359034e-06, 'epoch': 0.92}
{'loss': 1.2036, 'grad_norm': 0.6795335412025452, 'learning_rate': 1.668584579976985e-06, 'epoch': 0.97}
{'train_runtime': 1840.5918, 'train_samples_per_second': 15.111, 'train_steps_per_second': 0.472, 'train_loss': 2.134677513833699, 'epoch': 1.0}
DONE
