~/cs2281_synthetic_data ~/cs2281_synthetic_data
~/cs2281_synthetic_data ~/cs2281_synthetic_data ~/cs2281_synthetic_data
Running finetuning_summarization_no_eval.py
Saving results to results/summarization/t5-small_1_no_eval
Model name: google/flan-t5-small
Output directory: results/summarization/
Scratch directory: /n/netscratch/hlakkaraju_lab/Everyone/lilliansun/synthetic_data/
Unique save name: t5-small_1_no_eval
Dataset proportion: 1.0
Summarization train filepath: synthetic/summary_train.csv
Summarization val filepath: synthetic/summary_val.csv
Summarization test filepath: synthetic/summary_test.csv
Batch size: 8
Evaluation steps: 40
Size of input_ids tensor: torch.Size([3000]), dtype: torch.int64
Actual sequence length: 542
Size of input_ids tensor: torch.Size([2736]), dtype: torch.int64
Actual sequence length: 293
Size of input_ids tensor: torch.Size([3000]), dtype: torch.int64
Actual sequence length: 965
{'loss': 12.9274, 'grad_norm': 15.987411499023438, 'learning_rate': 4.942479148691401e-05, 'epoch': 0.01}
{'eval_loss': 5.03652811050415, 'eval_runtime': 54.4874, 'eval_samples_per_second': 63.813, 'eval_steps_per_second': 7.983, 'epoch': 0.01}
{'loss': 4.515, 'grad_norm': 8.973237991333008, 'learning_rate': 4.884958297382802e-05, 'epoch': 0.02}
{'eval_loss': 2.9359049797058105, 'eval_runtime': 54.4879, 'eval_samples_per_second': 63.812, 'eval_steps_per_second': 7.983, 'epoch': 0.02}
{'loss': 3.1085, 'grad_norm': 12.323822975158691, 'learning_rate': 4.827437446074202e-05, 'epoch': 0.03}
{'eval_loss': 2.447019577026367, 'eval_runtime': 54.4933, 'eval_samples_per_second': 63.806, 'eval_steps_per_second': 7.983, 'epoch': 0.03}
{'loss': 2.5995, 'grad_norm': 11.915169715881348, 'learning_rate': 4.7699165947656026e-05, 'epoch': 0.05}
{'eval_loss': 2.0634820461273193, 'eval_runtime': 54.4905, 'eval_samples_per_second': 63.809, 'eval_steps_per_second': 7.983, 'epoch': 0.05}
{'loss': 2.2616, 'grad_norm': 12.648160934448242, 'learning_rate': 4.712395743457003e-05, 'epoch': 0.06}
{'eval_loss': 1.7304365634918213, 'eval_runtime': 54.4866, 'eval_samples_per_second': 63.814, 'eval_steps_per_second': 7.984, 'epoch': 0.06}
{'loss': 1.9059, 'grad_norm': 10.145092010498047, 'learning_rate': 4.654874892148404e-05, 'epoch': 0.07}
{'eval_loss': 1.4836896657943726, 'eval_runtime': 54.4872, 'eval_samples_per_second': 63.813, 'eval_steps_per_second': 7.984, 'epoch': 0.07}
{'loss': 1.6281, 'grad_norm': 7.954967975616455, 'learning_rate': 4.5973540408398046e-05, 'epoch': 0.08}
{'eval_loss': 1.3506019115447998, 'eval_runtime': 54.4887, 'eval_samples_per_second': 63.811, 'eval_steps_per_second': 7.983, 'epoch': 0.08}
{'loss': 1.4715, 'grad_norm': 4.23122501373291, 'learning_rate': 4.539833189531205e-05, 'epoch': 0.09}
{'eval_loss': 1.2723230123519897, 'eval_runtime': 54.489, 'eval_samples_per_second': 63.811, 'eval_steps_per_second': 7.983, 'epoch': 0.09}
{'loss': 1.3844, 'grad_norm': 2.533198118209839, 'learning_rate': 4.4823123382226054e-05, 'epoch': 0.1}
{'eval_loss': 1.2351603507995605, 'eval_runtime': 54.4861, 'eval_samples_per_second': 63.814, 'eval_steps_per_second': 7.984, 'epoch': 0.1}
{'loss': 1.3002, 'grad_norm': 1.693284034729004, 'learning_rate': 4.4247914869140065e-05, 'epoch': 0.12}
{'eval_loss': 1.2094104290008545, 'eval_runtime': 54.4852, 'eval_samples_per_second': 63.816, 'eval_steps_per_second': 7.984, 'epoch': 0.12}
{'loss': 1.2657, 'grad_norm': 1.3219168186187744, 'learning_rate': 4.367270635605407e-05, 'epoch': 0.13}
{'eval_loss': 1.1935784816741943, 'eval_runtime': 54.4838, 'eval_samples_per_second': 63.817, 'eval_steps_per_second': 7.984, 'epoch': 0.13}
{'loss': 1.2346, 'grad_norm': 1.5615156888961792, 'learning_rate': 4.3097497842968074e-05, 'epoch': 0.14}
{'eval_loss': 1.180671215057373, 'eval_runtime': 54.4849, 'eval_samples_per_second': 63.816, 'eval_steps_per_second': 7.984, 'epoch': 0.14}
